import requests
from bs4 import BeautifulSoup


class Crawler:
    # Method for searching urls via href attribute
    @staticmethod
    def __search_href(soup, host):
        url_list = list()
        for url in soup.find_all('a', href=True):
            if url['href'].startswith('/') and host+url['href'] not in url_list:
                url_list.append(host+url['href'])
            elif host in url['href'] and url['href'] not in url_list:
                url_list.append(url['href'])
        return url_list

    # Method for providing urls from sites up to level 2
    @staticmethod
    def deep_crawl(url_list, host):
        deep_url_list = list()
        for url in url_list:
            for url2 in Crawler.find_url(url, host):
                if url2 not in deep_url_list:
                    deep_url_list.append(url2)
            if url not in deep_url_list:
                deep_url_list.append(url)
        return deep_url_list

    # Method that provides urls from single site
    @staticmethod
    def find_url(url, host=None):
        if host is None:
            host = url
        response = requests.get(url, allow_redirects=True)
        soup = BeautifulSoup(response.text, 'lxml')
        return Crawler.__search_href(soup, host)
